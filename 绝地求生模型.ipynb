{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "from timeit import default_timer as timer\n",
    "from sklearn import preprocessing\n",
    "from ultimate.mlp import MLP \n",
    "\n",
    "import gc, sys\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"E:/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_engineering(is_train=True):\n",
    "    # When this function is used for the training data, load train_V2.csv :\n",
    "    if is_train: \n",
    "        print(\"processing train_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'train_V2.csv')\n",
    "        \n",
    "        # Only take the samples with matches that have more than 1 player \n",
    "        # there are matches with no players or just one player ( those samples could affect our model badly) \n",
    "        df = df[df['maxPlace'] > 1]\n",
    "    \n",
    "    # When this function is used for the test data, load test_V2.csv :\n",
    "    else:\n",
    "        print(\"processing test_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'test_V2.csv')\n",
    "        \n",
    "    # Make a new feature indecating the total distance a player cut :\n",
    "    state('totalDistance')\n",
    "    s = timer()\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "    e = timer()\n",
    "    state('totalDistance', False, e - s)\n",
    "          \n",
    "\n",
    "    state('rankPoints')\n",
    "    s = timer()\n",
    "    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n",
    "    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n",
    "    e = timer()                                  \n",
    "    state('rankPoints', False, e-s)\n",
    "    \n",
    "\n",
    "    target = 'winPlacePerc'\n",
    "    # Get a list of the features to be used\n",
    "    features = list(df.columns)\n",
    "    \n",
    "    # Remove some features from the features list :\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchDuration\")\n",
    "    features.remove(\"matchType\")\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # If we are processing the training data, process the target\n",
    "    # (group the data by the match and the group then take the mean of the target) \n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        # Remove the target from the features list :\n",
    "        features.remove(target)\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by match and group ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "    \n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by match )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by match )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "     \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    \n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    # Drop matchId and groupId\n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "    \n",
    "    # X is the output dataset (without the target) and y is the target :\n",
    "    X = np.array(df_out, dtype=np.float64)\n",
    "    \n",
    "    \n",
    "    del df, df_out, agg, agg_rank\n",
    "    gc.collect()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def state(message,start = True, time = 0):\n",
    "    if(start):\n",
    "        print('Working on {} ... '.format(message))\n",
    "    else :\n",
    "        print('Working on {} took ({}) Sec \\n'.format(message,round(time , 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_V2.csv\n",
      "Working on totalDistance ... \n",
      "Working on totalDistance took (0.602) Sec \n",
      "\n",
      "Working on rankPoints ... \n",
      "Working on rankPoints took (0.087) Sec \n",
      "\n",
      "get group mean feature\n",
      "get group max feature\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Process the training data :\n",
    "x_train, y = feature_engineering(True)\n",
    "# Scale the data to be in the range (-1 , 1)\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape, x_train.max(), x_train.min())\n",
    "scaler.transform(x_train)\n",
    "print(\"x_train\", x_train.shape, x_train.max(), x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y * 2 - 1\n",
    "print(\"y\", y.shape, y.max(), y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epoch_train = 15\n",
    "mlp = MLP(layer_size=[x_train.shape[1], 28, 28, 28, 1], regularization=1, output_shrink=0.1, output_range=[-1,1], loss_type=\"hardmse\")\n",
    "mlp.train(x_train, y, verbose=0, iteration_log=20000, rate_init=0.08, rate_decay=0.8, epoch_train=epoch_train, epoch_decay=1)\n",
    "\n",
    "del x_train, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\"\"\"\n",
    "to run this kernel, pip install ultimate first from your custom packages\n",
    "\"\"\"\n",
    "from ultimate.mlp import MLP \n",
    "import gc\n",
    "\n",
    "df_train = pd.read_csv('E:/train_V2.csv')\n",
    "df_test = pd.read_csv('E:/test_V2.csv')\n",
    "\n",
    "\"\"\"\n",
    "it is a team game, scores within the same group is same, so let's get the feature of each group\n",
    "\"\"\"\n",
    "df_train_size = df_train.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "df_test_size = df_test.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "\n",
    "df_train_mean = df_train.groupby(['matchId','groupId']).mean().reset_index()\n",
    "df_test_mean = df_test.groupby(['matchId','groupId']).mean().reset_index()\n",
    "\n",
    "df_train_max = df_train.groupby(['matchId','groupId']).max().reset_index()\n",
    "df_test_max = df_test.groupby(['matchId','groupId']).max().reset_index()\n",
    "\n",
    "df_train_min = df_train.groupby(['matchId','groupId']).min().reset_index()\n",
    "df_test_min = df_test.groupby(['matchId','groupId']).min().reset_index()\n",
    "\n",
    "\"\"\"\n",
    "although you are a good game player, \n",
    "but if other players of other groups in the same match is better than you, you will still get little score\n",
    "so let's add the feature of each match\n",
    "\"\"\"\n",
    "df_train_match_mean = df_train.groupby(['matchId']).mean().reset_index()\n",
    "df_test_match_mean = df_test.groupby(['matchId']).mean().reset_index()\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_mean, suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n",
    "df_test = pd.merge(df_test, df_test_mean, suffixes=[\"\", \"_mean\"], how='left', on=['matchId', 'groupId'])\n",
    "del df_train_mean\n",
    "del df_test_mean\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_max, suffixes=[\"\", \"_max\"], how='left', on=['matchId', 'groupId'])\n",
    "df_test = pd.merge(df_test, df_test_max, suffixes=[\"\", \"_max\"], how='left', on=['matchId', 'groupId'])\n",
    "del df_train_max\n",
    "del df_test_max\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_min, suffixes=[\"\", \"_min\"], how='left', on=['matchId', 'groupId'])\n",
    "df_test = pd.merge(df_test, df_test_min, suffixes=[\"\", \"_min\"], how='left', on=['matchId', 'groupId'])\n",
    "del df_train_min\n",
    "del df_test_min\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_match_mean, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "df_test = pd.merge(df_test, df_test_match_mean, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "del df_train_match_mean\n",
    "del df_test_match_mean\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_size, how='left', on=['matchId', 'groupId'])\n",
    "df_test = pd.merge(df_test, df_test_size, how='left', on=['matchId', 'groupId'])\n",
    "del df_train_size\n",
    "del df_test_size\n",
    "\n",
    "target = 'winPlacePerc'\n",
    "train_columns = list(df_test.columns)\n",
    "\n",
    "\"\"\" remove some columns \"\"\"\n",
    "train_columns.remove(\"Id\")\n",
    "train_columns.remove(\"matchId\")\n",
    "train_columns.remove(\"groupId\")\n",
    "train_columns.remove(\"Id_mean\")\n",
    "train_columns.remove(\"Id_max\")\n",
    "train_columns.remove(\"Id_min\")\n",
    "train_columns.remove(\"Id_match_mean\")\n",
    "\n",
    "\"\"\"\n",
    "in this game, team skill level is more important than personal skill level \n",
    "maybe you are a newbe, but if your teammates are expert gamers, you will still get high score\n",
    "so let's remove the features of each player, just select the features of group and match\n",
    "\"\"\"\n",
    "train_columns_new = []\n",
    "for name in train_columns:\n",
    "    if '_' in name:\n",
    "        train_columns_new.append(name)\n",
    "train_columns = train_columns_new    \n",
    "print(train_columns)\n",
    "\n",
    "x_train = df_train[train_columns]\n",
    "x_test = df_test[train_columns]\n",
    "y = df_train[target]\n",
    "\n",
    "del df_train\n",
    "\n",
    "x_train = np.array(x_train, dtype=np.float64)\n",
    "x_test = np.array(x_test, dtype=np.float64)\n",
    "y = np.array(y, dtype=np.float64)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit(x_train)\n",
    "# scaler = preprocessing.QuantileTransformer().fit(x_train)\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "y = y*2 - 1\n",
    "\n",
    "print(\"x_train\", x_train.shape, x_train.min(), x_train.max())\n",
    "print(\"x_test\", x_test.shape, x_test.min(), x_test.max())\n",
    "print(\"y\", y.shape, y.min(), y.max())\n",
    "\n",
    "x_test = np.clip(x_test, a_min=-1, a_max=1)\n",
    "print(\"x_test\", x_test.shape, x_test.min(), x_test.max())\n",
    "\n",
    "mlp = MLP(layer_size=[x_train.shape[1], 28, 28, 28, 1], regularization=1, output_shrink=0.1, output_range=[-1,1], loss_type=\"hardmse\")\n",
    "\n",
    "\"\"\"\n",
    "train 15 epoches, batch_size=1, SGD\n",
    "\"\"\"\n",
    "mlp.train(x_train, y, verbose=2, iteration_log=20000, rate_init=0.08, rate_decay=0.8, epoch_train=15, epoch_decay=1)\n",
    "pred = mlp.predict(x_test)\n",
    "pred = pred.reshape(-1)\n",
    "\n",
    "pred = (pred + 1) / 2\n",
    "\n",
    "\"\"\"\n",
    "the following code is copied from other kernel\n",
    "\"\"\"\n",
    "df_test['winPlacePercPred'] = np.clip(pred, a_min=0, a_max=1)\n",
    "aux = df_test.groupby(['matchId','groupId'])['winPlacePercPred'].agg('mean').groupby('matchId').rank(pct=True).reset_index()\n",
    "aux.columns = ['matchId','groupId','winPlacePerc']\n",
    "df_test = df_test.merge(aux, how='left', on=['matchId','groupId'])\n",
    "    \n",
    "submission = df_test[['Id', 'winPlacePerc']]\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
